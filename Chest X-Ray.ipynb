{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 57, 57, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 57, 57, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 57, 57, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 29, 29, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 29, 29, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 15, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 15, 384)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,867,189\n",
      "Trainable params: 28,846,051\n",
      "Non-trainable params: 21,138\n",
      "_________________________________________________________________\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From <ipython-input-1-5c53c2258366>:122: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.9205 - accuracy: 0.7429WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 624 batches). You may need to use the repeat() function when building your dataset.\n",
      "16/16 [==============================] - 165s 10s/step - loss: 3.9205 - accuracy: 0.7429 - val_loss: 5.7185 - val_accuracy: 0.6250\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.9205 - accuracy: 0.7429WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 624 batches). You may need to use the repeat() function when building your dataset.\n",
      "16/16 [==============================] - 165s 10s/step - loss: 3.9205 - accuracy: 0.7429 - val_loss: 5.7185 - val_accuracy: 0.6250\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.9205 - accuracy: 0.7429 WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 624 batches). You may need to use the repeat() function when building your dataset.\n",
      "16/16 [==============================] - 167s 10s/step - loss: 3.9205 - accuracy: 0.7429 - val_loss: 5.7185 - val_accuracy: 0.6250\n",
      "WARNING:tensorflow:From <ipython-input-1-5c53c2258366>:127: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "Loss:  5.718464374542236 Accuracy:  0.625\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Activation, Dropout, Flatten, BatchNormalization, MaxPooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.backend import binary_crossentropy\n",
    "\n",
    "\n",
    "img_width, img_height = 227, 227\n",
    "\n",
    "train_data_path = '/Users/toobarahimnia/Documents/Software_projects/chest_xray/train'\n",
    "test_data_path = '/Users/toobarahimnia/Documents/Software_projects/chest_xray/test'\n",
    "train_sample_size = 5216\n",
    "test_sample_size = 624\n",
    "epochs = 3\n",
    "batch_size = 326\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "CoroNeuro = Sequential()\n",
    "\n",
    "#conv layer 1\n",
    "CoroNeuro.add(Conv2D(filters=96, input_shape=input_shape, kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "CoroNeuro.add(BatchNormalization())\n",
    "CoroNeuro.add(Activation('relu'))\n",
    "CoroNeuro.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "#conv layer 2\n",
    "CoroNeuro.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
    "CoroNeuro.add(BatchNormalization())\n",
    "CoroNeuro.add(Activation('relu'))\n",
    "CoroNeuro.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "#conv layer 3\n",
    "CoroNeuro.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "CoroNeuro.add(BatchNormalization())\n",
    "CoroNeuro.add(Activation('relu'))\n",
    "CoroNeuro.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "#conv layer 4\n",
    "CoroNeuro.add(Conv2D(filters=384,  kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "CoroNeuro.add(BatchNormalization())\n",
    "CoroNeuro.add(Activation('relu'))\n",
    "CoroNeuro.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "#conv layer 5\n",
    "CoroNeuro.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "CoroNeuro.add(BatchNormalization())\n",
    "CoroNeuro.add(Activation('relu'))\n",
    "CoroNeuro.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "\n",
    "#conv layer to dense/fully connected layer\n",
    "CoroNeuro.add(Flatten())\n",
    "\n",
    "#Dense layer 1\n",
    "CoroNeuro.add(Dense(4096, input_shape=(224, 224, 3)))\n",
    "CoroNeuro.add(BatchNormalization())\n",
    "CoroNeuro.add(Activation('relu'))\n",
    "CoroNeuro.add(Dropout(0.4))\n",
    "\n",
    "#Dense layer 2\n",
    "CoroNeuro.add(Dense(4096))\n",
    "CoroNeuro.add(BatchNormalization())\n",
    "CoroNeuro.add(Activation('relu'))\n",
    "CoroNeuro.add(Dropout(0.4))\n",
    "\n",
    "#Dense layer 2\n",
    "CoroNeuro.add(Dense(1000))\n",
    "CoroNeuro.add(BatchNormalization())\n",
    "CoroNeuro.add(Activation('relu'))\n",
    "CoroNeuro.add(Dropout(0.4))\n",
    "\n",
    "#Output layer\n",
    "CoroNeuro.add(Dense(1))\n",
    "CoroNeuro.add(BatchNormalization())\n",
    "CoroNeuro.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "#Summary\n",
    "CoroNeuro.summary()\n",
    "\n",
    "#Compilation\n",
    "CoroNeuro.compile(loss = binary_crossentropy, optimizer= 'adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Augmenting training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.25,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "#Augmenting testing data\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "#Training\n",
    "\n",
    "CoroNeuro.fit_generator(\n",
    "    train_generator,\n",
    "     \n",
    "    steps_per_epoch=train_sample_size // batch_size,\n",
    "    \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_sample_size)\n",
    "\n",
    "CoroNeuro.save_weights('coro_neuro.h5')\n",
    "\n",
    "#Evaluate accuracy\n",
    "score = CoroNeuro.evaluate_generator(test_generator, test_sample_size/batch_size, workers=1)\n",
    "\n",
    "#Print results\n",
    "print(\"Loss: \", score[0], \"Accuracy: \", score[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
